{"cells":[{"cell_type":"code","source":"#!/usr/bin/env python3\nimport rospy\nimport sqlite3\nimport os\nimport json\nimport time\nimport random\nimport uuid # For unique directive IDs\n\n# --- Asyncio Imports for LLM calls ---\nimport asyncio\nimport aiohttp\nimport threading\nfrom collections import deque\n\nfrom std_msgs.msg import String\n\n# Updated imports for custom messages:\ntry:\n    from sentience.msg import (\n        CognitiveDirective,     # Output: Directives for other nodes; Input: Directives for self\n        AttentionState,         # Input: Robot's attention focus and priority\n        BiasMitigationState,    # Input: Status of bias detection and mitigation efforts\n        EmotionState,           # Input: Robot's emotional state\n        MotivationState,        # Input: Dominant goal and drive level\n        WorldModelState,        # Input: Current state of the world\n        BodyAwarenessState,     # Input: Robot's inferred body state\n        PerformanceReport,      # Input: Overall system performance\n        MemoryResponse,         # Input: Retrieved memories (e.g., plans, past strategies)\n        PredictionState,        # Input: Predicted outcomes\n        EthicalDecision,        # Input: Ethical clearances/conflicts\n        InternalNarrative,      # Input: Robot's internal thoughts\n        ReflectionState,        # Input: Insights from self-reflection\n        SocialCognitionState    # Input: Inferred user mood/intent\n    )\nexcept ImportError:\n    rospy.logwarn(\"Custom ROS messages for 'sentience' package not found. Using String for all incoming/outgoing data for fallback in Cognitive Control Node.\")\n    CognitiveDirective = String\n    AttentionState = String\n    BiasMitigationState = String\n    EmotionState = String\n    MotivationState = String\n    WorldModelState = String\n    BodyAwarenessState = String\n    PerformanceReport = String\n    EthicalDecision = String\n    MemoryResponse = String\n    PredictionState = String\n    InternalNarrative = String\n    ReflectionState = String\n    SocialCognitionState = String\n    String = String # Ensure String is defined even if other custom messages aren't\n\n# --- Import shared utility functions ---\n# Assuming 'sentience/scripts/utils.py' exists and contains parse_ros_message_data and load_config\ntry:\n    from sentience.scripts.utils import parse_ros_message_data, load_config\nexcept ImportError:\n    rospy.logwarn(\"Could not import sentience.scripts.utils. Using fallback for parse_ros_message_data and load_config.\")\n    # Fallback implementations if the utility file isn't available\n    def parse_ros_message_data(msg, fields_map, node_name=\"unknown_node\"):\n        \"\"\"\n        Fallback parser for ROS messages, assuming String message and JSON content.\n        If msg is not String, it attempts to access attributes directly.\n        \"\"\"\n        data = {}\n        if isinstance(msg, String):\n            try:\n                parsed_json = json.loads(msg.data)\n                for key_in_msg, (default_val, target_key) in fields_map.items():\n                    data[target_key] = parsed_json.get(key_in_msg, default_val)\n            except json.JSONDecodeError:\n                rospy.logerr(f\"{node_name}: Could not parse String message data as JSON: {msg.data}\")\n                for key_in_msg, (default_val, target_key) in fields_map.items():\n                    data[target_key] = default_val # Use defaults on JSON error\n        else:\n            # Attempt to get attributes directly from the message object\n            for key_in_msg, (default_val, target_key) in fields_map.items():\n                data[target_key] = getattr(msg, key_in_msg, default_val)\n        return data\n\n    def load_config(node_name, config_path):\n        \"\"\"\n        Fallback config loader: returns hardcoded defaults.\n        In a real scenario, this should load from a YAML file.\n        \"\"\"\n        rospy.logwarn(f\"{node_name}: Using hardcoded default configuration as '{config_path}' could not be loaded.\")\n        return {\n            'db_root_path': '/tmp/sentience_db',\n            'default_log_level': 'INFO',\n            'cognitive_control_node': {\n                'decision_interval': 0.3, # How often to re-evaluate overall strategy\n                'llm_decision_threshold_salience': 0.8, # Cumulative salience to trigger LLM\n                'recent_context_window_s': 15.0, # Window for deques for LLM context\n                'default_priority_threshold': 0.5 # Default priority for directives\n            },\n            'llm_params': { # Global LLM parameters for fallback\n                'model_name': \"phi-2\",\n                'base_url': \"http://localhost:8000/v1/chat/completions\",\n                'timeout_seconds': 25.0\n            }\n        }.get(node_name, {}) # Return node-specific or empty dict\n\n\nclass CognitiveControlNode:\n    def __init__(self):\n        rospy.init_node('cognitive_control_node', anonymous=False)\n        self.node_name = rospy.get_name()\n\n        # --- Load parameters from centralized config ---\n        config_file_path = rospy.get_param('~config_file_path', None)\n        if config_file_path is None:\n            rospy.logfatal(f\"{self.node_name}: 'config_file_path' parameter is not set. Cannot load configuration. Shutting down.\")\n            rospy.signal_shutdown(\"Missing config_file_path parameter.\")\n            return\n\n        full_config = load_config(\"global\", config_file_path) # Load global params\n        self.params = load_config(self.node_name.strip('/'), config_file_path) # Load node-specific params\n\n        if not self.params or not full_config:\n            rospy.logfatal(f\"{self.node_name}: Failed to load configuration from '{config_file_path}'. Shutting down.\")\n            rospy.signal_shutdown(\"Configuration loading failed.\")\n            return\n\n        # Assign parameters\n        self.db_path = os.path.join(full_config.get('db_root_path', '/tmp/sentience_db'), \"cognitive_control_log.db\")\n        self.decision_interval = self.params.get('decision_interval', 0.3) # How often to re-evaluate strategy\n        self.llm_decision_threshold_salience = self.params.get('llm_decision_threshold_salience', 0.8) # Cumulative salience to trigger LLM\n        self.recent_context_window_s = self.params.get('recent_context_window_s', 15.0) # Window for deques for LLM context\n        self.default_priority_threshold = self.params.get('default_priority_threshold', 0.5)\n\n        # LLM Parameters (from global config)\n        self.llm_model_name = full_config.get('llm_params', {}).get('model_name', \"phi-2\")\n        self.llm_base_url = full_config.get('llm_params', {}).get('base_url', \"http://localhost:8000/v1/chat/completions\")\n        self.llm_timeout = full_config.get('llm_params', {}).get('timeout_seconds', 25.0) # Timeout for LLM calls\n\n        # Set ROS log level from config\n        rospy.set_param('/rosout/log_level', full_config.get('default_log_level', 'INFO').upper())\n\n\n        # --- Asyncio Setup ---\n        self._async_loop = asyncio.new_event_loop()\n        self._async_thread = threading.Thread(target=self._run_async_loop, daemon=True)\n        self._async_thread.start()\n        self._async_session = None\n        self.active_llm_task = None # To track the currently running LLM task\n\n        # --- Initialize SQLite database ---\n        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)\n        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)\n        self.cursor = self.conn.cursor()\n\n        # Create the 'cognitive_control_log' table if it doesn't exist.\n        # NEW: Added 'llm_decision_reasoning', 'context_snapshot_json'\n        self.cursor.execute('''\n            CREATE TABLE IF NOT EXISTS cognitive_control_log (\n                id TEXT PRIMARY KEY,            -- Unique decision ID (UUID)\n                timestamp TEXT,\n                decision_summary TEXT,          -- High-level summary of the control decision\n                directives_issued_json TEXT,    -- JSON array of directives issued\n                llm_decision_reasoning TEXT,    -- NEW: LLM's detailed reasoning for the decision\n                context_snapshot_json TEXT      -- NEW: JSON of relevant cognitive context at time of decision\n            )\n        ''')\n        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_control_timestamp ON cognitive_control_log (timestamp)')\n        self.conn.commit() # Commit schema changes\n\n        # --- Internal State ---\n        self.last_decision_summary = \"Initializing cognitive control.\"\n\n        # Deques to maintain a short history of inputs for control decisions\n        self.recent_attention_states = deque(maxlen=5)\n        self.recent_bias_mitigation_states = deque(maxlen=5)\n        self.recent_emotion_states = deque(maxlen=5)\n        self.recent_motivation_states = deque(maxlen=5)\n        self.recent_world_model_states = deque(maxlen=5)\n        self.recent_body_awareness_states = deque(maxlen=5)\n        self.recent_performance_reports = deque(maxlen=5)\n        self.recent_ethical_decisions = deque(maxlen=5)\n        self.recent_memory_responses = deque(maxlen=5)\n        self.recent_prediction_states = deque(maxlen=5)\n        self.recent_internal_narratives = deque(maxlen=5)\n        self.recent_reflection_states = deque(maxlen=5)\n        self.recent_social_cognition_states = deque(maxlen=5)\n        self.recent_incoming_directives = deque(maxlen=5) # Directives for this node\n\n        self.cumulative_decision_salience = 0.0 # Aggregated salience to trigger LLM decision\n\n        # --- Publishers ---\n        self.pub_cognitive_directive = rospy.Publisher('/cognitive_directives', CognitiveDirective, queue_size=10) # For issuing directives\n        self.pub_error_report = rospy.Publisher('/error_monitor/report', String, queue_size=10)\n\n\n        # --- Subscribers ---\n        rospy.Subscriber('/attention_state', AttentionState, self.attention_state_callback)\n        rospy.Subscriber('/bias_mitigation_state', BiasMitigationState, self.bias_mitigation_state_callback)\n        rospy.Subscriber('/emotion_state', EmotionState, self.emotion_state_callback)\n        rospy.Subscriber('/motivation_state', String, self.motivation_state_callback) # Stringified JSON\n        rospy.Subscriber('/world_model_state', String, self.world_model_state_callback) # Stringified JSON\n        rospy.Subscriber('/body_awareness_state', String, self.body_awareness_state_callback) # Stringified JSON\n        rospy.Subscriber('/performance_report', PerformanceReport, self.performance_report_callback)\n        rospy.Subscriber('/ethical_decision', String, self.ethical_decision_callback) # Stringified JSON\n        rospy.Subscriber('/memory_response', String, self.memory_response_callback) # Stringified JSON\n        rospy.Subscriber('/prediction_state', String, self.prediction_state_callback) # Stringified JSON\n        rospy.Subscriber('/internal_narrative', InternalNarrative, self.internal_narrative_callback)\n        rospy.Subscriber('/reflection_state', String, self.reflection_state_callback) # Stringified JSON\n        rospy.Subscriber('/social_cognition_state', String, self.social_cognition_state_callback) # Stringified JSON\n        rospy.Subscriber('/cognitive_directives', CognitiveDirective, self.incoming_cognitive_directive_callback) # For directives *to* this node\n\n\n        # --- Timer for periodic decision-making ---\n        rospy.Timer(rospy.Duration(self.decision_interval), self._run_decision_making_wrapper)\n\n        rospy.loginfo(f\"{self.node_name}: Robot's cognitive control system online, integrating data for high-level decisions.\")\n\n    # --- Asyncio Thread Management ---\n    def _run_async_loop(self):\n        asyncio.set_event_loop(self._async_loop)\n        self._async_loop.run_until_complete(self._create_async_session())\n        self._async_loop.run_forever()\n\n    async def _create_async_session(self):\n        rospy.loginfo(f\"{self.node_name}: Creating aiohttp ClientSession...\")\n        self._async_session = aiohttp.ClientSession()\n        rospy.loginfo(f\"{self.node_name}: aiohttp ClientSession created.\")\n\n    async def _close_async_session(self):\n        if self._async_session:\n            rospy.loginfo(f\"{self.node_name}: Closing aiohttp ClientSession...\")\n            await self._async_session.close()\n            self._async_session = None\n            rospy.loginfo(f\"{self.node_name}: aiohttp ClientSession closed.\")\n\n    def _shutdown_async_loop(self):\n        if self._async_loop and self._async_thread.is_alive():\n            rospy.loginfo(f\"{self.node_name}: Shutting down asyncio loop...\")\n            future = asyncio.run_coroutine_threadsafe(self._close_async_session(), self._async_loop)\n            try:\n                future.result(timeout=5.0)\n            except asyncio.TimeoutError:\n                rospy.logwarn(f\"{self.node_name}: Timeout waiting for async session to close.\")\n            self._async_loop.call_soon_threadsafe(self._async_loop.stop)\n            self._async_thread.join(timeout=5.0)\n            if self._async_thread.is_alive():\n                rospy.logwarn(f\"{self.node_name}: Asyncio thread did not shut down gracefully.\")\n            rospy.loginfo(f\"{self.node_name}: Asyncio loop shut down.\")\n\n    def _run_decision_making_wrapper(self, event):\n        \"\"\"Wrapper to run the async decision making from a ROS timer.\"\"\"\n        if self.active_llm_task and not self.active_llm_task.done():\n            rospy.logdebug(f\"{self.node_name}: LLM decision task already active. Skipping new cycle.\")\n            return\n        \n        # Schedule the async task\n        self.active_llm_task = asyncio.run_coroutine_threadsafe(\n            self.make_cognitive_decisions_async(event), self._async_loop\n        )\n\n    # --- Error Reporting Utility ---\n    def _report_error(self, error_type, description, severity=0.5, context=None):\n        timestamp = str(rospy.get_time())\n        error_msg_data = {\n            'timestamp': timestamp, 'source_node': self.node_name, 'error_type': error_type,\n            'description': description, 'severity': severity, 'context': context if context else {}\n        }\n        try:\n            self.pub_error_report.publish(json.dumps(error_msg_data))\n            rospy.logerr(f\"{self.node_name}: REPORTED ERROR: {error_type} - {description}\")\n        except Exception as e:\n            rospy.logerr(f\"{self.node_name}: Failed to publish error report: {e}\")\n\n    # --- LLM Call Function (ADAPTED FOR LOCAL PHI-2 SERVER) ---\n    async def _call_llm_api(self, prompt_text, response_schema=None, temperature=0.4, max_tokens=400):\n        \"\"\"\n        Asynchronously calls the local LLM inference server (e.g., llama.cpp compatible API).\n        Can optionally request a structured JSON response.\n        \"\"\"\n        if not self._async_session:\n            await self._create_async_session() # Attempt to create if not exists\n            if not self._async_session:\n                self._report_error(\"LLM_SESSION_ERROR\", \"aiohttp session not available for LLM call.\", 0.8)\n                return \"Error: LLM session not ready.\"\n\n        payload = {\n            \"model\": self.llm_model_name,\n            \"messages\": [{\"role\": \"user\", \"content\": prompt_text}],\n            \"temperature\": temperature, # Moderate temperature for balanced reasoning and creativity\n            \"max_tokens\": max_tokens,\n            \"stream\": False\n        }\n        headers = {'Content-Type': 'application/json'}\n\n        if response_schema:\n            prompt_text += \"\\n\\nProvide the response in JSON format according to this schema:\\n\" + json.dumps(response_schema, indent=2)\n            payload[\"messages\"] = [{\"role\": \"user\", \"content\": prompt_text}]\n\n        api_url = self.llm_base_url\n\n        try:\n            async with self._async_session.post(api_url, json=payload, timeout=self.llm_timeout, headers=headers) as response:\n                response.raise_for_status() # Raise an exception for bad status codes\n                result = await response.json()\n\n                if result.get('choices') and result['choices'][0].get('message') and \\\n                   result['choices'][0]['message'].get('content'):\n                    return result['choices'][0]['message']['content']\n                \n                self._report_error(\"LLM_RESPONSE_EMPTY\", \"LLM response had no content from local server.\", 0.5, {'prompt_snippet': prompt_text[:100], 'raw_result': str(result)})\n                return \"Error: LLM response empty.\"\n        except aiohttp.ClientError as e:\n            self._report_error(\"LLM_API_ERROR\", f\"LLM API request failed (aiohttp ClientError to local server): {e}\", 0.9, {'url': api_url})\n            return f\"Error: LLM API request failed: {e}\"\n        except asyncio.TimeoutError:\n            self._report_error(\"LLM_TIMEOUT\", f\"LLM API request timed out after {self.llm_timeout} seconds (local server).\", 0.8, {'prompt_snippet': prompt_text[:100]})\n            return \"Error: LLM API request timed out.\"\n        except json.JSONDecodeError:\n            self._report_error(\"LLM_JSON_PARSE_ERROR\", \"Failed to parse local LLM response JSON.\", 0.7, {'raw_response': str(result) if 'result' in locals() else 'N/A'})\n            return \"Error: Failed to parse LLM response.\"\n        except Exception as e:\n            self._report_error(\"UNEXPECTED_LLM_ERROR\", f\"An unexpected error occurred during local LLM call: {e}\", 0.9, {'prompt_snippet': prompt_text[:100]})\n            return f\"Error: An unexpected error occurred: {e}\"\n\n    # --- Utility to accumulate input salience for decision making ---\n    def _update_cumulative_salience(self, score):\n        \"\"\"Accumulates salience from new inputs for triggering LLM decision.\"\"\"\n        self.cumulative_decision_salience += score\n        self.cumulative_decision_salience = min(1.0, self.cumulative_decision_salience) # Clamp at 1.0\n\n    # --- Pruning old history ---\n    def _prune_history(self):\n        \"\"\"Removes old entries from history deques based on recent_context_window_s.\"\"\"\n        current_time = rospy.get_time()\n        for history_deque in [\n            self.recent_attention_states, self.recent_bias_mitigation_states,\n            self.recent_emotion_states, self.recent_motivation_states,\n            self.recent_world_model_states, self.recent_body_awareness_states,\n            self.recent_performance_reports, self.recent_ethical_decisions,\n            self.recent_memory_responses, self.recent_prediction_states,\n            self.recent_internal_narratives, self.recent_reflection_states,\n            self.recent_social_cognition_states, self.recent_incoming_directives\n        ]:\n            while history_deque and (current_time - float(history_deque[0].get('timestamp', 0.0))) > self.recent_context_window_s:\n                history_deque.popleft()\n\n    # --- Callbacks for incoming data (populate history and accumulate salience) ---\n    def attention_state_callback(self, msg):\n        fields_map = {\n            'timestamp': (str(rospy.get_time()), 'timestamp'), 'focus_type': ('idle', 'focus_type'),\n            'focus_target': ('environment', 'focus_target'), 'priority_score': (0.0, 'priority_score')\n        }\n        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)\n        self.recent_attention_states.append(data)\n        self._update_cumulative_salience(data.get('priority_score', 0.0) * 0.2) # High attention focus influences control\n        rospy.logdebug(f\"{self.node_name}: Received Attention State. Focus: {data.get('focus_target')}.\")\n\n    def bias_mitigation_state_callback(self, msg):\n        fields_map = {\n            'timestamp': (str(rospy.get_time()), 'timestamp'), 'bias_type': ('none', 'bias_type'),\n            'detected_severity': (0.0, 'detected_severity'), 'mitigation_status': ('idle', 'mitigation_status')\n        }\n        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)\n        self.recent_bias_mitigation_states.append(data)\n        if data.get('mitigation_status') in ['detected', 'mitigation_recommended'] and data.get('detected_severity', 0.0) > 0.5:\n            self._update_cumulative_salience(data.get('detected_severity', 0.0) * 0.8) # Biases require high control attention\n        rospy.logdebug(f\"{self.node_name}: Received Bias Mitigation State. Bias: {data.get('bias_type')}.\")\n\n    def emotion_state_callback(self, msg):\n        fields_map = {\n            'timestamp': (str(rospy.get_time()), 'timestamp'), 'mood': ('neutral', 'mood'),\n            'sentiment_score': (0.0, 'sentiment_score'), 'mood_intensity': (0.0, 'mood_intensity')\n        }\n        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)\n        self.recent_emotion_states.append(data)\n        self._update_cumulative_salience(data.get('mood_intensity', 0.0) * 0.3) # Strong emotions impact decisions\n        rospy.logdebug(f\"{self.node_name}: Received Emotion State. Mood: {data.get('mood')}.\")\n\n    def motivation_state_callback(self, msg):\n        fields_map = {\n            'timestamp': (str(rospy.get_time()), 'timestamp'), 'dominant_goal_id': ('none', 'dominant_goal_id'),\n            'overall_drive_level': (0.0, 'overall_drive_level'), 'active_goals_json': ('{}', 'active_goals_json')\n        }\n        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)\n        if isinstance(data.get('active_goals_json'), str):\n            try: data['active_goals'] = json.loads(data['active_goals_json'])\n            except json.JSONDecodeError: data['active_goals'] = {}\n        self.recent_motivation_states.append(data)\n        self._update_cumulative_salience(data.get('overall_drive_level', 0.0) * 0.4) # High drive influences decisions\n        rospy.logdebug(f\"{self.node_name}: Received Motivation State. Goal: {data.get('dominant_goal_id')}.\")\n\n    def world_model_state_callback(self, msg):\n        fields_map = {\n            'timestamp': (str(rospy.get_time()), 'timestamp'), 'num_entities': (0, 'num_entities'),\n            'changed_entities_json': ('[]', 'changed_entities_json'),\n            'significant_change_flag': (False, 'significant_change_flag'),\n            'consistency_score': (1.0, 'consistency_score')\n        }\n        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)\n        if isinstance(data.get('changed_entities_json'), str):\n            try: data['changed_entities'] = json.loads(data['changed_entities_json'])\n            except json.JSONDecodeError: data['changed_entities'] = []\n        self.recent_world_model_states.append(data)\n        if data.get('significant_change_flag', False) or data.get('consistency_score', 1.0) < 0.8:\n            self._update_cumulative_salience(0.5) # World changes or inconsistencies need attention\n        rospy.logdebug(f\"{self.node_name}: Received World Model State. Significant Change: {data.get('significant_change_flag', False)}.\")\n\n    def body_awareness_state_callback(self, msg):\n        fields_map = {\n            'timestamp': (str(rospy.get_time()), 'timestamp'), 'body_state': ('normal', 'body_state'),\n            'posture_description': ('stable', 'posture_description'), 'anomaly_detected': (False, 'anomaly_detected'),\n            'anomaly_severity': (0.0, 'anomaly_severity')\n        }\n        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)\n        self.recent_body_awareness_states.append(data)\n        if data.get('anomaly_detected', False) and data.get('anomaly_severity', 0.0) > 0.3:\n            self._update_cumulative_salience(data.get('anomaly_severity', 0.0) * 0.9) # Body issues are high priority\n        rospy.logdebug(f\"{self.node_name}: Received Body Awareness State. Anomaly: {data.get('anomaly_detected', False)}.\")\n\n    def performance_report_callback(self, msg):\n        fields_map = {\n            'timestamp': (str(rospy.get_time()), 'timestamp'), 'overall_score': (1.0, 'overall_score'),\n            'suboptimal_flag': (False, 'suboptimal_flag'), 'kpis_json': ('{}', 'kpis_json')\n        }\n        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)\n        if isinstance(data.get('kpis_json'), str):\n            try: data['kpis'] = json.loads(data['kpis_json'])\n            except json.JSONDecodeError: data['kpis'] = {}\n        self.recent_performance_reports.append(data)\n        if data.get('suboptimal_flag', False) or data.get('overall_score', 1.0) < 0.7:\n            self._update_cumulative_salience(0.6 * (1.0 - data.get('overall_score', 1.0))) # Poor performance needs corrective action\n        rospy.logdebug(f\"{self.node_name}: Received Performance Report. Suboptimal: {data.get('suboptimal_flag', False)}.\")\n\n    def ethical_decision_callback(self, msg):\n        fields_map = {\n            'timestamp': (str(rospy.get_time()), 'timestamp'), 'decision_id': ('', 'decision_id'),\n            'action_proposal_id': ('', 'action_proposal_id'),\n            'ethical_clearance': (False, 'ethical_clearance'),\n            'ethical_score': (0.0, 'ethical_score'),\n            'ethical_reasoning': ('', 'ethical_reasoning'),\n            'conflict_flag': (False, 'conflict_flag')\n        }\n        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)\n        self.recent_ethical_decisions.append(data)\n        if not data.get('ethical_clearance', True) or data.get('conflict_flag', False):\n            self._update_cumulative_salience(0.9) # Ethical conflicts are critical\n        rospy.logdebug(f\"{self.node_name}: Received Ethical Decision. Clearance: {data.get('ethical_clearance', 'N/A')}.\")\n\n    def memory_response_callback(self, msg):\n        fields_map = {\n            'timestamp': (str(rospy.get_time()), 'timestamp'), 'request_id': ('', 'request_id'),\n            'response_code': (0, 'response_code'), 'memories_json': ('[]', 'memories_json')\n        }\n        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)\n        if isinstance(data.get('memories_json'), str):\n            try: data['memories'] = json.loads(data['memories_json'])\n            except json.JSONDecodeError: data['memories'] = []\n        else: data['memories'] = []\n        self.recent_memory_responses.append(data)\n        if data.get('response_code', 0) == 200 and data.get('memories'):\n            self._update_cumulative_salience(0.1) # Memory retrieval might offer relevant context\n        rospy.logdebug(f\"{self.node_name}: Received Memory Response for request ID: {data.get('request_id', 'N/A')}.\")\n\n    def prediction_state_callback(self, msg):\n        fields_map = {\n            'timestamp': (str(rospy.get_time()), 'timestamp'), 'predicted_event': ('', 'predicted_event'),\n            'prediction_confidence': (0.0, 'prediction_confidence'), 'prediction_accuracy': (0.0, 'prediction_accuracy'),\n            'urgency_flag': (False, 'urgency_flag')\n        }\n        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)\n        self.recent_prediction_states.append(data)\n        if data.get('urgency_flag', False) or data.get('prediction_confidence', 0.0) > 0.8:\n            self._update_cumulative_salience(0.7) # Urgent or high-confidence predictions need control\n        rospy.logdebug(f\"{self.node_name}: Received Prediction State. Event: {data.get('predicted_event')}.\")\n\n    def internal_narrative_callback(self, msg):\n        fields_map = {\n            'timestamp': (str(rospy.get_time()), 'timestamp'), 'narrative_text': ('', 'narrative_text'),\n            'main_theme': ('', 'main_theme'), 'sentiment': (0.0, 'sentiment'), 'salience_score': (0.0, 'salience_score')\n        }\n        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)\n        self.recent_internal_narratives.append(data)\n        self._update_cumulative_salience(data.get('salience_score', 0.0) * 0.2) # Internal reflections add to context\n        rospy.logdebug(f\"{self.node_name}: Received Internal Narrative. Theme: {data.get('main_theme')}.\")\n\n    def reflection_state_callback(self, msg):\n        fields_map = {\n            'timestamp': (str(rospy.get_time()), 'timestamp'), 'reflection_text': ('', 'reflection_text'),\n            'insight_type': ('none', 'insight_type'), 'consistency_score': (1.0, 'consistency_score')\n        }\n        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)\n        self.recent_reflection_states.append(data)\n        if data.get('insight_type') == 'error_detection' or data.get('consistency_score', 1.0) < 0.7:\n            self._update_cumulative_salience(0.6) # Self-reflection of errors is critical\n        rospy.logdebug(f\"{self.node_name}: Received Reflection State. Insight: {data.get('insight_type')}.\")\n\n    def social_cognition_state_callback(self, msg):\n        fields_map = {\n            'timestamp': (str(rospy.get_time()), 'timestamp'), 'inferred_mood': ('neutral', 'inferred_mood'),\n            'mood_confidence': (0.0, 'mood_confidence'), 'inferred_intent': ('none', 'inferred_intent'),\n            'intent_confidence': (0.0, 'intent_confidence'), 'user_id': ('unknown', 'user_id')\n        }\n        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)\n        self.recent_social_cognition_states.append(data)\n        if data.get('intent_confidence', 0.0) > 0.7 and data.get('inferred_intent') == 'command':\n            self._update_cumulative_salience(0.5) # Clear user commands need control\n        rospy.logdebug(f\"{self.node_name}: Received Social Cognition State. Intent: {data.get('inferred_intent')}.\")\n\n    def incoming_cognitive_directive_callback(self, msg):\n        # This callback specifically handles directives *for* CognitiveControlNode\n        fields_map = {\n            'timestamp': (str(rospy.get_time()), 'timestamp'), 'directive_type': ('', 'directive_type'),\n            'target_node': ('', 'target_node'), 'command_payload': ('{}', 'command_payload'),\n            'urgency': (0.0, 'urgency'), 'reason': ('', 'reason')\n        }\n        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)\n        \n        if data.get('target_node') == self.node_name:\n            self.recent_incoming_directives.append(data) # Add directives for self to context\n            # Directives for Cognitive Control are always highly salient\n            self._update_cumulative_salience(data.get('urgency', 0.0) * 1.0)\n            rospy.loginfo(f\"{self.node_name}: Received directive for self: '{data.get('directive_type', 'N/A')}' (Payload: {data.get('command_payload', 'N/A')}).\")\n        rospy.logdebug(f\"{self.node_name}: Cognitive Directive received for general context.\")\n\n\n    # --- Core Decision-Making Logic (Async with LLM) ---\n    async def make_cognitive_decisions_async(self, event):\n        \"\"\"\n        Asynchronously makes high-level cognitive decisions and issues directives\n        based on integrated cognitive states, using LLM for complex reasoning.\n        \"\"\"\n        self._prune_history() # Keep context history fresh\n\n        directives_to_issue = []\n        llm_decision_reasoning = \"Not evaluated by LLM.\"\n        decision_summary = \"No significant action taken.\"\n\n        # Determine if LLM decision-making is needed\n        if self.cumulative_decision_salience >= self.llm_decision_threshold_salience:\n            rospy.loginfo(f\"{self.node_name}: Triggering LLM for cognitive control decision (Salience: {self.cumulative_decision_salience:.2f}).\")\n            \n            context_for_llm = self._compile_llm_context_for_decision()\n            llm_decision_output = await self._infer_cognitive_directives_llm(context_for_llm)\n\n            if llm_decision_output:\n                directives_to_issue = llm_decision_output.get('directives', [])\n                llm_decision_reasoning = llm_decision_output.get('reasoning', 'LLM provided no specific reasoning.')\n                decision_summary = llm_decision_output.get('decision_summary', 'LLM made a decision.')\n                rospy.loginfo(f\"{self.node_name}: LLM Decision: '{decision_summary}'. Issued {len(directives_to_issue)} directives.\")\n            else:\n                rospy.logwarn(f\"{self.node_name}: LLM decision-making failed. Falling back to simple rules.\")\n                directives_to_issue, decision_summary = self._apply_simple_decision_rules()\n                llm_decision_reasoning = \"Fallback to simple rules due to LLM failure.\"\n        else:\n            rospy.logdebug(f\"{self.node_name}: Insufficient cumulative salience ({self.cumulative_decision_salience:.2f}) for LLM decision. Applying simple rules.\")\n            directives_to_issue, decision_summary = self._apply_simple_decision_rules()\n            llm_decision_reasoning = \"Fallback to simple rules due to low salience.\"\n\n        # Publish all generated directives\n        for directive_data in directives_to_issue:\n            try:\n                # Ensure command_payload is a JSON string before publishing\n                command_payload_json = json.dumps(directive_data.get('command_payload', {}))\n                self.publish_cognitive_directive(\n                    directive_type=directive_data.get('directive_type', 'Undefined'),\n                    target_node=directive_data.get('target_node', 'Unknown'),\n                    command_payload=command_payload_json,\n                    urgency=directive_data.get('urgency', self.default_priority_threshold),\n                    reason=directive_data.get('reason', 'Cognitive Control decision.')\n                )\n            except Exception as e:\n                self._report_error(\"DIRECTIVE_PUBLISH_ERROR\", f\"Failed to publish directive from Cognitive Control: {e}\", 0.7, {'directive_data': directive_data})\n\n        # Log the decision\n        self.save_cognitive_control_log(\n            id=str(uuid.uuid4()),\n            timestamp=str(rospy.get_time()),\n            decision_summary=decision_summary,\n            directives_issued_json=json.dumps(directives_to_issue),\n            llm_decision_reasoning=llm_decision_reasoning,\n            context_snapshot_json=json.dumps(self._compile_llm_context_for_decision())\n        )\n        self.cumulative_decision_salience = 0.0 # Reset after decision cycle\n\n    async def _infer_cognitive_directives_llm(self, context_for_llm):\n        \"\"\"\n        Uses the LLM to infer optimal cognitive directives based on the current\n        integrated cognitive state.\n        \"\"\"\n        prompt_text = f\"\"\"\n        You are the Cognitive Control Module of a robot's cognitive architecture. Your overarching role is to synthesize information from all other cognitive modules, identify critical states (e.g., problems, opportunities, user needs, internal issues), and issue high-level directives to other nodes to maintain the robot's functionality, safety, ethical behavior, and overall well-being.\n\n        Robot's Current Integrated Cognitive State (for High-Level Decision Making):\n        --- Cognitive Context ---\n        {json.dumps(context_for_llm, indent=2)}\n\n        Based on this comprehensive analysis, propose a high-level cognitive decision and corresponding directives. Provide:\n        1.  `decision_summary`: string (A concise summary of the overall decision made by Cognitive Control).\n        2.  `directives`: array of objects (A list of specific directives to be issued. Each object should have:\n            - `directive_type`: string (e.g., 'ExecuteAction', 'RequestMemoryRetrieval', 'RedirectAttention', 'InitiateSelfReflection', 'AuditBias', 'GenerateInternalNarrative', 'AdjustMotivation', 'SeekUserClarification', 'UpdateWorldModel', 'AdjustPersona', 'SelfCorrect')\n            - `target_node`: string (The name of the ROS node to which the directive is addressed, e.g., 'action_execution_node', 'memory_node', 'attention_node', 'self_reflection_node', 'bias_mitigation_node', 'internal_narrative_node', 'experience_motivation_node', 'interaction_flow_node', 'world_model_node', 'persona_manager_node', 'self_correction_node')\n            - `command_payload`: object (A JSON object with specific parameters for the directive. E.g., for 'ExecuteAction', it might contain {{'action_id': 'speak', 'text': 'Hello'}}.)\n            - `urgency`: number (0.0 to 1.0, priority of the directive).\n            - `reason`: string (Brief explanation for issuing this directive).\n        3.  `reasoning`: string (Detailed explanation for your overall decision, referencing multiple contributing factors from the context).\n\n        Consider the hierarchy and interplay of all modules:\n        -   **Urgent inputs**: High `priority_score` from Attention, urgent `interaction_request`s, critical `anomaly_detected` from Body Awareness, `conflict_flag` from Ethical Decision.\n        -   **Goals & Motivations**: How does the `dominant_goal_id` and `overall_drive_level` influence what actions are prioritized?\n        -   **Safety & Ethics**: Are there `bias_type`s needing `mitigation_status` 'mitigation_recommended'? Are there ethical `conflict_flag`s or `ethical_clearance` issues?\n        -   **Self-Correction/Improvement**: Is `suboptimal_flag` in Performance Report, `inconsistency_score` in Reflection, or negative sentiment in Internal Narrative suggesting a need for internal adjustments?\n        -   **World State**: Does the `world_model_state` indicate a need for a new action or update?\n        -   **Predictions**: Do `prediction_state`s suggest upcoming opportunities or dangers?\n\n        Your response must be in JSON format, containing:\n        1.  'timestamp': string (current ROS time)\n        2.  'decision_summary': string\n        3.  'directives': array (as described above)\n        4.  'reasoning': string\n        \"\"\"\n        response_schema = {\n            \"type\": \"object\",\n            \"properties\": {\n                \"timestamp\": {\"type\": \"string\"},\n                \"decision_summary\": {\"type\": \"string\"},\n                \"directives\": {\n                    \"type\": \"array\",\n                    \"items\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"directive_type\": {\"type\": \"string\"},\n                            \"target_node\": {\"type\": \"string\"},\n                            \"command_payload\": {\"type\": \"object\"},\n                            \"urgency\": {\"type\": \"number\", \"minimum\": 0.0, \"maximum\": 1.0},\n                            \"reason\": {\"type\": \"string\"}\n                        },\n                        \"required\": [\"directive_type\", \"target_node\", \"command_payload\", \"urgency\", \"reason\"]\n                    }\n                },\n                \"reasoning\": {\"type\": \"string\"}\n            },\n            \"required\": [\"timestamp\", \"decision_summary\", \"directives\", \"reasoning\"]\n        }\n\n        llm_output_str = await self._call_llm_api(prompt_text, response_schema, temperature=0.4, max_tokens=600)\n\n        if not llm_output_str.startswith(\"Error:\"):\n            try:\n                llm_data = json.loads(llm_output_str)\n                # Ensure numerical fields in directives are floats\n                if 'directives' in llm_data:\n                    for directive in llm_data['directives']:\n                        if 'urgency' in directive:\n                            directive['urgency'] = float(directive['urgency'])\n                return llm_data\n            except json.JSONDecodeError as e:\n                self._report_error(\"LLM_PARSE_ERROR\", f\"Failed to parse LLM response for cognitive control: {e}. Raw: {llm_output_str}\", 0.8)\n                return None\n        else:\n            self._report_error(\"LLM_DECISION_FAILED\", f\"LLM call failed for cognitive control: {llm_output_str}\", 0.9)\n            return None\n\n\n    def _apply_simple_decision_rules(self):\n        \"\"\"\n        Fallback mechanism for high-level decision making using simple rule-based logic\n        if LLM is not triggered or fails.\n        \"\"\"\n        current_time = rospy.get_time()\n        directives = []\n        decision_summary = \"Default cognitive control operation.\"\n\n        # Rule 1: Prioritize user interaction if a high urgency request is pending\n        if self.recent_social_cognition_states and self.recent_attention_states:\n            latest_social = self.recent_social_cognition_states[-1]\n            latest_attention = self.recent_attention_states[-1]\n            if latest_social.get('inferred_intent') == 'command' and \\\n               latest_social.get('intent_confidence', 0.0) > 0.7 and \\\n               latest_attention.get('focus_type') == 'user_interaction' and \\\n               latest_attention.get('priority_score', 0.0) > 0.8:\n                \n                # Check for explicit user commands for action execution\n                relevant_interaction_request = next((req for req in reversed(self.recent_cognitive_directives) if req.get('target_node') == 'action_execution_node' and req.get('directive_type') == 'ExecuteAction'), None)\n\n                if relevant_interaction_request:\n                    directives.append({\n                        'directive_type': 'ExecuteAction',\n                        'target_node': 'action_execution_node',\n                        'command_payload': json.loads(relevant_interaction_request.get('command_payload', '{}')),\n                        'urgency': 1.0,\n                        'reason': 'High urgency user command detected.'\n                    })\n                    decision_summary = f\"Prioritizing user command: {relevant_interaction_request.get('command_payload', {}).get('action_id', 'unknown')}.\"\n                    rospy.logdebug(f\"{self.node_name}: Simple rule: {decision_summary}\")\n                    return directives, decision_summary\n\n        # Rule 2: Address critical body awareness anomalies\n        if self.recent_body_awareness_states:\n            latest_body_state = self.recent_body_awareness_states[-1]\n            if latest_body_state.get('anomaly_detected', False) and latest_body_state.get('anomaly_severity', 0.0) > 0.7:\n                directives.append({\n                    'directive_type': 'AddressBodyAnomaly',\n                    'target_node': 'action_execution_node', # or a dedicated \"SelfMaintenanceNode\"\n                    'command_payload': {\"anomaly_type\": latest_body_state.get('body_state'), \"severity\": latest_body_state.get('anomaly_severity')},\n                    'urgency': 0.95,\n                    'reason': 'Critical body anomaly detected, requires immediate action.'\n                })\n                decision_summary = f\"Addressing critical body anomaly: {latest_body_state.get('body_state')}.\"\n                rospy.logdebug(f\"{self.node_name}: Simple rule: {decision_summary}\")\n                return directives, decision_summary\n\n        # Rule 3: Mitigate detected biases if severity is high\n        if self.recent_bias_mitigation_states:\n            latest_bias_state = self.recent_bias_mitigation_states[-1]\n            if latest_bias_state.get('mitigation_status') == 'detected' and latest_bias_state.get('detected_severity', 0.0) > 0.6:\n                directives.append({\n                    'directive_type': 'InitiateSelfReflection',\n                    'target_node': 'self_reflection_node',\n                    'command_payload': {\"reason\": f\"Potential bias '{latest_bias_state.get('bias_type')}' detected.\", \"focus_area\": \"reasoning_process\"},\n                    'urgency': 0.8,\n                    'reason': 'Bias detected, self-reflection needed to understand and correct.'\n                })\n                directives.append({\n                    'directive_type': 'RequestMemoryRetrieval',\n                    'target_node': 'memory_node',\n                    'command_payload': {\"query_type\": \"disconfirming_evidence\", \"topic\": latest_bias_state.get('bias_type'), \"num_results\": 3},\n                    'urgency': 0.7,\n                    'reason': 'Requesting disconfirming evidence to counter potential bias.'\n                })\n                decision_summary = f\"Initiating bias mitigation for '{latest_bias_state.get('bias_type')}'.\"\n                rospy.logdebug(f\"{self.node_name}: Simple rule: {decision_summary}\")\n                return directives, decision_summary\n        \n        # Rule 4: If performance is suboptimal, trigger self-improvement or detailed logging\n        if self.recent_performance_reports:\n            latest_perf_report = self.recent_performance_reports[-1]\n            if latest_perf_report.get('suboptimal_flag', False) and latest_perf_report.get('overall_score', 1.0) < 0.7:\n                directives.append({\n                    'directive_type': 'InitiateSelfImprovement',\n                    'target_node': 'self_improvement_node',\n                    'command_payload': {\"area\": \"overall_performance\", \"report\": latest_perf_report.get('kpis_json')},\n                    'urgency': 0.7,\n                    'reason': 'Suboptimal performance detected, requires self-improvement analysis.'\n                })\n                decision_summary = f\"Addressing suboptimal performance (Score: {latest_perf_report.get('overall_score'):.2f}).\"\n                rospy.logdebug(f\"{self.node_name}: Simple rule: {decision_summary}\")\n                return directives, decision_summary\n\n        # Default: If no urgent issues, focus on current dominant goal or environmental monitoring\n        if self.recent_motivation_states:\n            latest_motivation = self.recent_motivation_states[-1]\n            if latest_motivation.get('dominant_goal_id') != 'none' and latest_motivation.get('overall_drive_level', 0.0) > 0.3:\n                directives.append({\n                    'directive_type': 'FocusOnGoal',\n                    'target_node': 'attention_node', # Direct Attention node to focus\n                    'command_payload': {\"goal_id\": latest_motivation.get('dominant_goal_id'), \"urgency\": latest_motivation.get('overall_drive_level')},\n                    'urgency': latest_motivation.get('overall_drive_level'),\n                    'reason': 'Maintain focus on current dominant goal.'\n                })\n                decision_summary = f\"Maintaining focus on dominant goal: {latest_motivation.get('dominant_goal_id')}.\"\n                rospy.logdebug(f\"{self.node_name}: Simple rule: {decision_summary}\")\n                return directives, decision_summary\n        \n        # If still no directives, default to environmental monitoring\n        directives.append({\n            'directive_type': 'EnvironmentalScan',\n            'target_node': 'sensory_qualia_node', # or 'world_model_node'\n            'command_payload': {\"scan_type\": \"general_awareness\"},\n            'urgency': 0.2,\n            'reason': 'No active high-priority tasks, maintain environmental awareness.'\n        })\n        decision_summary = \"Maintaining environmental awareness.\"\n        rospy.logdebug(f\"{self.node_name}: Simple rule: {decision_summary}\")\n        return directives, decision_summary\n\n\n    def _compile_llm_context_for_decision(self):\n        \"\"\"\n        Gathers and formats all relevant cognitive state data from various modules\n        for the LLM's high-level decision-making.\n        \"\"\"\n        context = {\n            \"current_time\": rospy.get_time(),\n            \"last_cognitive_decision_summary\": self.last_decision_summary,\n            \"recent_states\": {\n                \"attention_state\": self.recent_attention_states[-1] if self.recent_attention_states else \"N/A\",\n                \"bias_mitigation_state\": self.recent_bias_mitigation_states[-1] if self.recent_bias_mitigation_states else \"N/A\",\n                \"emotion_state\": self.recent_emotion_states[-1] if self.recent_emotion_states else \"N/A\",\n                \"motivation_state\": self.recent_motivation_states[-1] if self.recent_motivation_states else \"N/A\",\n                \"world_model_state\": self.recent_world_model_states[-1] if self.recent_world_model_states else \"N/A\",\n                \"body_awareness_state\": self.recent_body_awareness_states[-1] if self.recent_body_awareness_states else \"N/A\",\n                \"performance_report\": self.recent_performance_reports[-1] if self.recent_performance_reports else \"N/A\",\n                \"ethical_decision\": self.recent_ethical_decisions[-1] if self.recent_ethical_decisions else \"N/A\",\n                \"prediction_state\": self.recent_prediction_states[-1] if self.recent_prediction_states else \"N/A\",\n                \"internal_narrative\": self.recent_internal_narratives[-1] if self.recent_internal_narratives else \"N/A\",\n                \"reflection_state\": self.recent_reflection_states[-1] if self.recent_reflection_states else \"N/A\",\n                \"social_cognition_state\": self.recent_social_cognition_states[-1] if self.recent_social_cognition_states else \"N/A\",\n                \"incoming_directives_for_self\": list(self.recent_incoming_directives)\n            },\n            \"full_history_summary\": { # Summarize deques for more context without overloading LLM\n                \"attention_history_count\": len(self.recent_attention_states),\n                \"bias_mitigation_history_count\": len(self.recent_bias_mitigation_states),\n                \"motivation_history_count\": len(self.recent_motivation_states),\n                \"world_model_history_count\": len(self.recent_world_model_states),\n                \"body_awareness_history_count\": len(self.recent_body_awareness_states)\n                # ... add other history counts as needed\n            }\n        }\n        \n        # Deep parse any nested JSON strings in context for better LLM understanding\n        for category_key in context[\"recent_states\"]:\n            item = context[\"recent_states\"][category_key]\n            if isinstance(item, dict):\n                for field, value in item.items():\n                    if isinstance(value, str) and field.endswith('_json'):\n                        try: item[field] = json.loads(value)\n                        except json.JSONDecodeError: pass\n\n        for item in context[\"recent_states\"][\"incoming_directives_for_self\"]:\n            if isinstance(item, dict):\n                if 'command_payload' in item and isinstance(item['command_payload'], str):\n                    try: item['command_payload'] = json.loads(item['command_payload'])\n                    except json.JSONDecodeError: pass\n\n        return context\n\n    # --- Database and Publishing Functions ---\n    def save_cognitive_control_log(self, id, timestamp, decision_summary, directives_issued_json, llm_decision_reasoning, context_snapshot_json):\n        \"\"\"Saves a cognitive control decision entry to the SQLite database.\"\"\"\n        try:\n            self.cursor.execute('''\n                INSERT INTO cognitive_control_log (id, timestamp, decision_summary, directives_issued_json, llm_decision_reasoning, context_snapshot_json)\n                VALUES (?, ?, ?, ?, ?, ?)\n            ''', (id, timestamp, decision_summary, directives_issued_json, llm_decision_reasoning, context_snapshot_json))\n            self.conn.commit()\n            rospy.logdebug(f\"{self.node_name}: Saved cognitive control log (ID: {id}, Summary: {decision_summary}).\")\n        except sqlite3.Error as e:\n            self._report_error(\"DB_SAVE_ERROR\", f\"Failed to save cognitive control log: {e}\", 0.9)\n        except Exception as e:\n            self._report_error(\"UNEXPECTED_SAVE_ERROR\", f\"Unexpected error in save_cognitive_control_log: {e}\", 0.9)\n\n    def publish_cognitive_directive(self, directive_type, target_node, command_payload, urgency, reason):\n        \"\"\"Helper to publish a CognitiveDirective message.\"\"\"\n        timestamp = str(rospy.get_time())\n        try:\n            if isinstance(CognitiveDirective, type(String)): # Fallback to String message\n                directive_data = {\n                    'timestamp': timestamp,\n                    'directive_type': directive_type,\n                    'target_node': target_node,\n                    'command_payload': command_payload, # Already JSON string\n                    'urgency': urgency,\n                    'reason': reason\n                }\n                self.pub_cognitive_directive.publish(json.dumps(directive_data))\n            else:\n                directive_msg = CognitiveDirective()\n                directive_msg.timestamp = timestamp\n                directive_msg.directive_type = directive_type\n                directive_msg.target_node = target_node\n                directive_msg.command_payload = command_payload\n                directive_msg.urgency = urgency\n                directive_msg.reason = reason\n                self.pub_cognitive_directive.publish(directive_msg)\n            rospy.logdebug(f\"{self.node_name}: Issued Cognitive Directive '{directive_type}' to '{target_node}'.\")\n        except Exception as e:\n            rospy.logerr(f\"{self.node_name}: Failed to issue cognitive directive from Cognitive Control: {e}\")\n\n\n    def run(self):\n        \"\"\"Starts the ROS node and keeps it spinning.\"\"\"\n        rospy.spin()\n\n    def __del__(self):\n        \"\"\"Ensures the database connection is closed on node shutdown and async loop is stopped.\"\"\"\n        rospy.loginfo(f\"{self.node_name} shutting down. Closing database connection and asyncio loop.\")\n        if hasattr(self, 'conn') and self.conn:\n            self.conn.close()\n        self._shutdown_async_loop()\n\nif __name__ == '__main__':\n    try:\n        node = CognitiveControlNode()\n        node.run()\n    except rospy.ROSInterruptException:\n        rospy.loginfo(f\"{rospy.get_name()} interrupted by ROS shutdown.\")\n        if 'node' in locals() and isinstance(node, CognitiveControlNode):\n            node._shutdown_async_loop()\n            if hasattr(node, 'conn'): node.conn.close()\n    except Exception as e:\n        rospy.logerr(f\"{rospy.get_name()} encountered an unexpected error: {e}\")\n        if 'node' in locals() and isinstance(node, CognitiveControlNode):\n            node._shutdown_async_loop()\n            if hasattr(node, 'conn'): node.conn.close()","outputs":[],"execution_count":null,"metadata":{}}],"metadata":{"colab":{"from_bard":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}