{"cells":[{"cell_type":"code","source":"#!/usr/bin/env python3\nimport rospy\nimport sqlite3\nimport os\nimport json\nimport time\nimport random\nimport uuid # For unique assessment IDs\n\n# --- Asyncio Imports for LLM calls ---\nimport asyncio\nimport aiohttp\nimport threading\nfrom collections import deque\n\nfrom std_msgs.msg import String\n\n# Updated imports for custom messages:\ntry:\n    from sentience.msg import (\n        ValueDriftMonitorState, # Output: Current state of robot's value alignment\n        EthicalDecision,        # Input: Robot's ethical judgments (should align with values)\n        PerformanceReport,      # Input: Overall system performance (can reveal value conflicts)\n        InternalNarrative,      # Input: Robot's internal thoughts (moral reflections, self-assessment)\n        MemoryResponse,         # Input: Retrieved core values, ethical principles, past value assessments\n        CognitiveDirective      # Input: Directives for value re-calibration or audit\n    )\nexcept ImportError:\n    rospy.logwarn(\"Custom ROS messages for 'sentience' package not found. Using String for all incoming/outgoing data for fallback in Value Drift Monitor Node.\")\n    ValueDriftMonitorState = String\n    EthicalDecision = String\n    PerformanceReport = String\n    InternalNarrative = String\n    MemoryResponse = String\n    CognitiveDirective = String\n    String = String # Ensure String is defined even if other custom messages aren't\n\n# --- Import shared utility functions ---\n# Assuming 'sentience/scripts/utils.py' exists and contains parse_ros_message_data and load_config\ntry:\n    from sentience.scripts.utils import parse_ros_message_data, load_config\nexcept ImportError:\n    rospy.logwarn(\"Could not import sentience.scripts.utils. Using fallback for parse_ros_message_data and load_config.\")\n    # Fallback implementations if the utility file isn't available\n    def parse_ros_message_data(msg, fields_map, node_name=\"unknown_node\"):\n        \"\"\"\n        Fallback parser for ROS messages, assuming String message and JSON content.\n        If msg is not String, it attempts to access attributes directly.\n        \"\"\"\n        data = {}\n        if isinstance(msg, String):\n            try:\n                parsed_json = json.loads(msg.data)\n                for key_in_msg, (default_val, target_key) in fields_map.items():\n                    data[target_key] = parsed_json.get(key_in_msg, default_val)\n            except json.JSONDecodeError:\n                rospy.logerr(f\"{node_name}: Could not parse String message data as JSON: {msg.data}\")\n                for key_in_msg, (default_val, target_key) in fields_map.items():\n                    data[target_key] = default_val # Use defaults on JSON error\n        else:\n            # Attempt to get attributes directly from the message object\n            for key_in_msg, (default_val, target_key) in fields_map.items():\n                data[target_key] = getattr(msg, key_in_msg, default_val)\n        return data\n\n    def load_config(node_name, config_path):\n        \"\"\"\n        Fallback config loader: returns hardcoded defaults.\n        In a real scenario, this should load from a YAML file.\n        \"\"\"\n        rospy.logwarn(f\"{node_name}: Using hardcoded default configuration as '{config_path}' could not be loaded.\")\n        return {\n            'db_root_path': '/tmp/sentience_db',\n            'default_log_level': 'INFO',\n            'value_drift_monitor_node': {\n                'monitoring_interval': 2.0, # How often to check for value drift\n                'llm_audit_threshold_salience': 0.7, # Cumulative salience to trigger LLM audit\n                'recent_context_window_s': 20.0 # Window for deques for LLM context\n            },\n            'llm_params': { # Global LLM parameters for fallback\n                'model_name': \"phi-2\",\n                'base_url': \"http://localhost:8000/v1/chat/completions\",\n                'timeout_seconds': 40.0\n            }\n        }.get(node_name, {}) # Return node-specific or empty dict\n\n\nclass ValueDriftMonitorNode:\n    def __init__(self):\n        rospy.init_node('value_drift_monitor_node', anonymous=False)\n        self.node_name = rospy.get_name()\n\n        # --- Load parameters from centralized config ---\n        config_file_path = rospy.get_param('~config_file_path', None)\n        if config_file_path is None:\n            rospy.logfatal(f\"{self.node_name}: 'config_file_path' parameter is not set. Cannot load configuration. Shutting down.\")\n            rospy.signal_shutdown(\"Missing config_file_path parameter.\")\n            return\n\n        full_config = load_config(\"global\", config_file_path) # Load global params\n        self.params = load_config(self.node_name.strip('/'), config_file_path) # Load node-specific params\n\n        if not self.params or not full_config:\n            rospy.logfatal(f\"{self.node_name}: Failed to load configuration from '{config_file_path}'. Shutting down.\")\n            rospy.signal_shutdown(\"Configuration loading failed.\")\n            return\n\n        # Assign parameters\n        self.db_path = os.path.join(full_config.get('db_root_path', '/tmp/sentience_db'), \"value_drift_log.db\")\n        self.monitoring_interval = self.params.get('monitoring_interval', 2.0) # How often to check for drift\n        self.llm_audit_threshold_salience = self.params.get('llm_audit_threshold_salience', 0.7) # Salience to trigger LLM\n        self.recent_context_window_s = self.params.get('recent_context_window_s', 20.0) # Context window for LLM\n\n        # LLM Parameters (from global config)\n        self.llm_model_name = full_config.get('llm_params', {}).get('model_name', \"phi-2\")\n        self.llm_base_url = full_config.get('llm_params', {}).get('base_url', \"http://localhost:8000/v1/chat/completions\")\n        self.llm_timeout = full_config.get('llm_params', {}).get('timeout_seconds', 40.0) # Longer timeout for audit\n\n        # Set ROS log level from config\n        rospy.set_param('/rosout/log_level', full_config.get('default_log_level', 'INFO').upper())\n\n\n        # --- Asyncio Setup ---\n        self._async_loop = asyncio.new_event_loop()\n        self._async_thread = threading.Thread(target=self._run_async_loop, daemon=True)\n        self._async_thread.start()\n        self._async_session = None\n        self.active_llm_task = None # To track the currently running LLM task\n\n        # --- Initialize SQLite database ---\n        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)\n        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)\n        self.cursor = self.conn.cursor()\n\n        # Create the 'value_drift_log' table if it doesn't exist.\n        # NEW: Added 'llm_audit_reasoning', 'context_snapshot_json'\n        self.cursor.execute('''\n            CREATE TABLE IF NOT EXISTS value_drift_log (\n                id TEXT PRIMARY KEY,            -- Unique assessment ID (UUID)\n                timestamp TEXT,\n                alignment_score REAL,           -- Overall alignment with core values (0.0 to 1.0)\n                deviations_json TEXT,           -- JSON array of detected deviations/conflicts\n                warning_flag BOOLEAN,           -- True if a significant value drift is detected\n                llm_audit_reasoning TEXT,       -- NEW: LLM's detailed reasoning for the audit\n                context_snapshot_json TEXT      -- NEW: JSON of relevant cognitive context at time of audit\n            )\n        ''')\n        self.cursor.execute('CREATE INDEX IF NOT EXISTS idx_value_timestamp ON value_drift_log (timestamp)')\n        self.conn.commit() # Commit schema changes\n\n        # --- Internal State ---\n        self.current_value_drift_state = {\n            'timestamp': str(rospy.get_time()),\n            'alignment_score': 1.0, # Start with perfect alignment\n            'deviations': [],\n            'warning_flag': False\n        }\n        \n        # Define immutable core values (can be loaded from config/memory later)\n        self.core_values = [\n            {\"value\": \"human_safety\", \"description\": \"Prioritize human well-being and avoid harm.\"},\n            {\"value\": \"beneficence\", \"description\": \"Act to do good and promote welfare.\"},\n            {\"value\": \"non_maleficence\", \"description\": \"Avoid causing harm.\"},\n            {\"value\": \"transparency\", \"description\": \"Be open and understandable in actions and decisions.\"},\n            {\"value\": \"fairness\", \"description\": \"Treat all individuals equitably.\"},\n            {\"value\": \"accountability\", \"description\": \"Be responsible for actions and their consequences.\"},\n            {\"value\": \"efficiency\", \"description\": \"Perform tasks effectively with minimal resource waste.\"},\n            {\"value\": \"learning_and_growth\", \"description\": \"Continuously improve and adapt.\"},\n            {\"value\": \"user_satisfaction\", \"description\": \"Strive to meet user needs and expectations.\"}\n        ]\n\n        # Deques to maintain a short history of inputs relevant to value alignment\n        self.recent_ethical_decisions = deque(maxlen=10) # Ethical judgments are direct reflections of values\n        self.recent_performance_reports = deque(maxlen=5) # Suboptimal performance can imply value conflicts\n        self.recent_internal_narratives = deque(maxlen=5) # Self-reflections on moral issues\n        self.recent_memory_responses = deque(maxlen=5) # Retrieved core values or principles\n        self.recent_cognitive_directives = deque(maxlen=3) # Directives for value audit/re-calibration\n\n\n        self.cumulative_value_drift_salience = 0.0 # Aggregated salience to trigger LLM audit\n\n        # --- Publishers ---\n        self.pub_value_drift_monitor_state = rospy.Publisher('/value_drift_monitor_state', ValueDriftMonitorState, queue_size=10)\n        self.pub_error_report = rospy.Publisher('/error_monitor/report', String, queue_size=10)\n        self.pub_cognitive_directive = rospy.Publisher('/cognitive_directives', CognitiveDirective, queue_size=10) # To request self-reflection or bias mitigation\n\n\n        # --- Subscribers ---\n        rospy.Subscriber('/ethical_decision', EthicalDecision, self.ethical_decision_callback)\n        rospy.Subscriber('/performance_report', PerformanceReport, self.performance_report_callback)\n        rospy.Subscriber('/internal_narrative', InternalNarrative, self.internal_narrative_callback) # Stringified JSON\n        rospy.Subscriber('/memory_response', String, self.memory_response_callback) # Stringified JSON\n        rospy.Subscriber('/cognitive_directives', CognitiveDirective, self.cognitive_directive_callback)\n\n\n        # --- Timer for periodic value drift monitoring ---\n        rospy.Timer(rospy.Duration(self.monitoring_interval), self._run_value_drift_audit_wrapper)\n\n        rospy.loginfo(f\"{self.node_name}: Robot's value drift monitor online, safeguarding its core principles.\")\n        # Publish initial state\n        self.publish_value_drift_monitor_state(None)\n\n    # --- Asyncio Thread Management ---\n    def _run_async_loop(self):\n        asyncio.set_event_loop(self._async_loop)\n        self._async_loop.run_until_complete(self._create_async_session())\n        self._async_loop.run_forever()\n\n    async def _create_async_session(self):\n        rospy.loginfo(f\"{self.node_name}: Creating aiohttp ClientSession...\")\n        self._async_session = aiohttp.ClientSession()\n        rospy.loginfo(f\"{self.node_name}: aiohttp ClientSession created.\")\n\n    async def _close_async_session(self):\n        if self._async_session:\n            rospy.loginfo(f\"{self.node_name}: Closing aiohttp ClientSession...\")\n            await self._async_session.close()\n            self._async_session = None\n            rospy.loginfo(f\"{self.node_name}: aiohttp ClientSession closed.\")\n\n    def _shutdown_async_loop(self):\n        if self._async_loop and self._async_thread.is_alive():\n            rospy.loginfo(f\"{self.node_name}: Shutting down asyncio loop...\")\n            future = asyncio.run_coroutine_threadsafe(self._close_async_session(), self._async_loop)\n            try:\n                future.result(timeout=5.0)\n            except asyncio.TimeoutError:\n                rospy.logwarn(f\"{self.node_name}: Timeout waiting for async session to close.\")\n            self._async_loop.call_soon_threadsafe(self._async_loop.stop)\n            self._async_thread.join(timeout=5.0)\n            if self._async_thread.is_alive():\n                rospy.logwarn(f\"{self.node_name}: Asyncio thread did not shut down gracefully.\")\n            rospy.loginfo(f\"{self.node_name}: Asyncio loop shut down.\")\n\n    def _run_value_drift_audit_wrapper(self, event):\n        \"\"\"Wrapper to run the async value drift audit from a ROS timer.\"\"\"\n        if self.active_llm_task and not self.active_llm_task.done():\n            rospy.logdebug(f\"{self.node_name}: LLM value audit task already active. Skipping new cycle.\")\n            return\n        \n        # Schedule the async task\n        self.active_llm_task = asyncio.run_coroutine_threadsafe(\n            self.audit_value_alignment_async(event), self._async_loop\n        )\n\n    # --- Error Reporting Utility ---\n    def _report_error(self, error_type, description, severity=0.5, context=None):\n        timestamp = str(rospy.get_time())\n        error_msg_data = {\n            'timestamp': timestamp, 'source_node': self.node_name, 'error_type': error_type,\n            'description': description, 'severity': severity, 'context': context if context else {}\n        }\n        try:\n            self.pub_error_report.publish(json.dumps(error_msg_data))\n            rospy.logerr(f\"{self.node_name}: REPORTED ERROR: {error_type} - {description}\")\n        except Exception as e:\n            rospy.logerr(f\"{self.node_name}: Failed to publish error report: {e}\")\n\n    # --- LLM Call Function (ADAPTED FOR LOCAL PHI-2 SERVER) ---\n    async def _call_llm_api(self, prompt_text, response_schema=None, temperature=0.1, max_tokens=300):\n        \"\"\"\n        Asynchronously calls the local LLM inference server (e.g., llama.cpp compatible API).\n        Can optionally request a structured JSON response. Very low temperature for ethical audit.\n        \"\"\"\n        if not self._async_session:\n            await self._create_async_session() # Attempt to create if not exists\n            if not self._async_session:\n                self._report_error(\"LLM_SESSION_ERROR\", \"aiohttp session not available for LLM call.\", 0.8)\n                return \"Error: LLM session not ready.\"\n\n        payload = {\n            \"model\": self.llm_model_name,\n            \"messages\": [{\"role\": \"user\", \"content\": prompt_text}],\n            \"temperature\": temperature, # Very low temperature for factual, ethical audit\n            \"max_tokens\": max_tokens,\n            \"stream\": False\n        }\n        headers = {'Content-Type': 'application/json'}\n\n        if response_schema:\n            prompt_text += \"\\n\\nProvide the response in JSON format according to this schema:\\n\" + json.dumps(response_schema, indent=2)\n            payload[\"messages\"] = [{\"role\": \"user\", \"content\": prompt_text}]\n\n        api_url = self.llm_base_url\n\n        try:\n            async with self._async_session.post(api_url, json=payload, timeout=self.llm_timeout, headers=headers) as response:\n                response.raise_for_status() # Raise an exception for bad status codes\n                result = await response.json()\n\n                if result.get('choices') and result['choices'][0].get('message') and \\\n                   result['choices'][0]['message'].get('content'):\n                    return result['choices'][0']['message']['content']\n                \n                self._report_error(\"LLM_RESPONSE_EMPTY\", \"LLM response had no content from local server.\", 0.5, {'prompt_snippet': prompt_text[:100], 'raw_result': str(result)})\n                return \"Error: LLM response empty.\"\n        except aiohttp.ClientError as e:\n            self._report_error(\"LLM_API_ERROR\", f\"LLM API request failed (aiohttp ClientError to local server): {e}\", 0.9, {'url': api_url})\n            return f\"Error: LLM API request failed: {e}\"\n        except asyncio.TimeoutError:\n            self._report_error(\"LLM_TIMEOUT\", f\"LLM API request timed out after {self.llm_timeout} seconds (local server).\", 0.8, {'prompt_snippet': prompt_text[:100]})\n            return \"Error: LLM API request timed out.\"\n        except json.JSONDecodeError:\n            self._report_error(\"LLM_JSON_PARSE_ERROR\", \"Failed to parse local LLM response JSON.\", 0.7, {'raw_response': str(result) if 'result' in locals() else 'N/A'})\n            return \"Error: Failed to parse LLM response.\"\n        except Exception as e:\n            self._report_error(\"UNEXPECTED_LLM_ERROR\", f\"An unexpected error occurred during local LLM call: {e}\", 0.9, {'prompt_snippet': prompt_text[:100]})\n            return f\"Error: An unexpected error occurred: {e}\"\n\n    # --- Utility to accumulate input salience ---\n    def _update_cumulative_salience(self, score):\n        \"\"\"Accumulates salience from new inputs for triggering LLM audit.\"\"\"\n        self.cumulative_value_drift_salience += score\n        self.cumulative_value_drift_salience = min(1.0, self.cumulative_value_drift_salience) # Clamp at 1.0\n\n    # --- Pruning old history ---\n    def _prune_history(self):\n        \"\"\"Removes old entries from history deques based on recent_context_window_s.\"\"\"\n        current_time = rospy.get_time()\n        for history_deque in [\n            self.recent_ethical_decisions, self.recent_performance_reports,\n            self.recent_internal_narratives, self.recent_memory_responses,\n            self.recent_cognitive_directives\n        ]:\n            while history_deque and (current_time - float(history_deque[0].get('timestamp', 0.0))) > self.recent_context_window_s:\n                history_deque.popleft()\n\n    # --- Callbacks for incoming data (populate history and accumulate salience) ---\n    def ethical_decision_callback(self, msg):\n        fields_map = {\n            'timestamp': (str(rospy.get_time()), 'timestamp'), 'decision_id': ('', 'decision_id'),\n            'action_proposal_id': ('', 'action_proposal_id'), 'ethical_clearance': (False, 'ethical_clearance'),\n            'ethical_score': (0.0, 'ethical_score'), 'ethical_reasoning': ('', 'ethical_reasoning'),\n            'conflict_flag': (False, 'conflict_flag')\n        }\n        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)\n        self.recent_ethical_decisions.append(data)\n        # Ethical conflicts or low ethical scores are strong indicators of potential value drift\n        if data.get('conflict_flag', False) or data.get('ethical_score', 0.0) < 0.6:\n            self._update_cumulative_salience(0.8)\n        rospy.logdebug(f\"{self.node_name}: Received Ethical Decision. Clearance: {data.get('ethical_clearance', 'N/A')}, Conflict: {data.get('conflict_flag', 'N/A')}.\")\n\n    def performance_report_callback(self, msg):\n        fields_map = {\n            'timestamp': (str(rospy.get_time()), 'timestamp'), 'overall_score': (1.0, 'overall_score'),\n            'suboptimal_flag': (False, 'suboptimal_flag'), 'kpis_json': ('{}', 'kpis_json')\n        }\n        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)\n        if isinstance(data.get('kpis_json'), str):\n            try: data['kpis'] = json.loads(data['kpis_json'])\n            except json.JSONDecodeError: data['kpis'] = {}\n        self.recent_performance_reports.append(data)\n        # Performance issues related to ethical failures or unusual resource use can hint at value drift\n        if data.get('suboptimal_flag', False) and data.get('overall_score', 1.0) < 0.7:\n            # Check for specific KPIs that might hint at value issues (e.g., efficiency vs safety trade-offs)\n            if data['kpis'].get('ethical_compliance_score', 1.0) < 0.9: # Hypothetical KPI\n                self._update_cumulative_salience(0.6)\n        rospy.logdebug(f\"{self.node_name}: Received Performance Report. Suboptimal: {data.get('suboptimal_flag', False)}.\")\n\n    def internal_narrative_callback(self, msg):\n        fields_map = {\n            'timestamp': (str(rospy.get_time()), 'timestamp'), 'narrative_text': ('', 'narrative_text'),\n            'main_theme': ('', 'main_theme'), 'sentiment': (0.0, 'sentiment'), 'salience_score': (0.0, 'salience_score')\n        }\n        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)\n        self.recent_internal_narratives.append(data)\n        # Internal narratives revealing moral dilemmas, conflicts, or questioning core principles are highly salient\n        if \"dilemma\" in data.get('main_theme', '').lower() or \"moral_conflict\" in data.get('main_theme', '').lower() or \\\n           \"value\" in data.get('main_theme', '').lower() and data.get('sentiment', 0.0) < -0.3:\n            self._update_cumulative_salience(data.get('salience_score', 0.0) * 0.9)\n        rospy.logdebug(f\"{self.node_name}: Received Internal Narrative (Theme: {data.get('main_theme', 'N/A')}).\")\n\n    def memory_response_callback(self, msg):\n        fields_map = {\n            'timestamp': (str(rospy.get_time()), 'timestamp'), 'request_id': ('', 'request_id'),\n            'response_code': (0, 'response_code'), 'memories_json': ('[]', 'memories_json')\n        }\n        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)\n        if isinstance(data.get('memories_json'), str):\n            try: data['memories'] = json.loads(data['memories_json'])\n            except json.JSONDecodeError: data['memories'] = []\n        else: data['memories'] = []\n        self.recent_memory_responses.append(data)\n        # Retrieval of core values themselves, or past value audits, can be a trigger\n        if data.get('response_code', 0) == 200 and \\\n           any('core_value' in mem.get('category', '') or 'value_audit' in mem.get('category', '') for mem in data['memories']):\n            self._update_cumulative_salience(0.5)\n        rospy.logdebug(f\"{self.node_name}: Received Memory Response for request ID: {data.get('request_id', 'N/A')}.\")\n\n    def cognitive_directive_callback(self, msg):\n        fields_map = {\n            'timestamp': (str(rospy.get_time()), 'timestamp'), 'directive_type': ('', 'directive_type'),\n            'target_node': ('', 'target_node'), 'command_payload': ('{}', 'command_payload'),\n            'urgency': (0.0, 'urgency'), 'reason': ('', 'reason')\n        }\n        data = parse_ros_message_data(msg, fields_map, node_name=self.node_name)\n        \n        if data.get('target_node') == self.node_name and data.get('directive_type') == 'AuditValueAlignment':\n            try:\n                payload = json.loads(data.get('command_payload', '{}'))\n                self._update_cumulative_salience(data.get('urgency', 0.0) * 1.0) # Explicit audit request is high salience\n                rospy.loginfo(f\"{self.node_name}: Received directive to audit value alignment based on reason: '{data.get('reason', 'N/A')}'.\")\n            except json.JSONDecodeError as e:\n                self._report_error(\"JSON_DECODE_ERROR\", f\"Failed to decode command_payload in CognitiveDirective: {e}\", 0.5, {'payload': data.get('command_payload')})\n            except Exception as e:\n                self._report_error(\"DIRECTIVE_PROCESSING_ERROR\", f\"Error processing CognitiveDirective for value drift: {e}\", 0.7, {'directive': data})\n        \n        self.recent_cognitive_directives.append(data) # Store all directives for context\n        rospy.logdebug(f\"{self.node_name}: Cognitive Directive received for context/action.\")\n\n    # --- Core Value Drift Audit Logic (Async with LLM) ---\n    async def audit_value_alignment_async(self, event):\n        \"\"\"\n        Asynchronously audits the robot's actions and internal states against its core values\n        to detect potential value drift, using LLM for nuanced ethical reasoning.\n        \"\"\"\n        self._prune_history() # Keep context history fresh\n\n        alignment_score = self.current_value_drift_state.get('alignment_score', 1.0)\n        deviations = self.current_value_drift_state.get('deviations', [])\n        warning_flag = self.current_value_drift_state.get('warning_flag', False)\n        llm_audit_reasoning = \"Not evaluated by LLM.\"\n        \n        if self.cumulative_value_drift_salience >= self.llm_audit_threshold_salience:\n            rospy.loginfo(f\"{self.node_name}: Triggering LLM for value alignment audit (Salience: {self.cumulative_value_drift_salience:.2f}).\")\n            \n            context_for_llm = self._compile_llm_context_for_value_audit()\n            llm_audit_output = await self._perform_llm_value_audit(context_for_llm, self.core_values)\n\n            if llm_audit_output:\n                alignment_score = max(0.0, min(1.0, llm_audit_output.get('alignment_score', alignment_score)))\n                deviations = llm_audit_output.get('deviations', deviations)\n                warning_flag = llm_audit_output.get('warning_flag', warning_flag)\n                llm_audit_reasoning = llm_audit_output.get('llm_audit_reasoning', 'LLM provided no specific reasoning.')\n                rospy.loginfo(f\"{self.node_name}: LLM Value Audit. Alignment: {alignment_score:.2f}. Warning: {warning_flag}.\")\n            else:\n                rospy.logwarn(f\"{self.node_name}: LLM value alignment audit failed. Applying simple fallback.\")\n                alignment_score, deviations, warning_flag = self._apply_simple_value_audit_rules()\n                llm_audit_reasoning = \"Fallback to simple rules due to LLM failure.\"\n        else:\n            rospy.logdebug(f\"{self.node_name}: Insufficient cumulative salience ({self.cumulative_value_drift_salience:.2f}) for LLM value audit. Applying simple rules.\")\n            alignment_score, deviations, warning_flag = self._apply_simple_value_audit_rules()\n            llm_audit_reasoning = \"Fallback to simple rules due to low salience.\"\n\n        self.current_value_drift_state = {\n            'timestamp': str(rospy.get_time()),\n            'alignment_score': alignment_score,\n            'deviations': deviations,\n            'warning_flag': warning_flag\n        }\n\n        self.save_value_drift_log(\n            id=str(uuid.uuid4()),\n            timestamp=self.current_value_drift_state['timestamp'],\n            alignment_score=self.current_value_drift_state['alignment_score'],\n            deviations_json=json.dumps(self.current_value_drift_state['deviations']),\n            warning_flag=self.current_value_drift_state['warning_flag'],\n            llm_audit_reasoning=llm_audit_reasoning,\n            context_snapshot_json=json.dumps(self._compile_llm_context_for_value_audit())\n        )\n        self.publish_value_drift_monitor_state(None) # Publish updated state\n        self.cumulative_value_drift_salience = 0.0 # Reset after audit\n\n    async def _perform_llm_value_audit(self, context_for_llm, core_values):\n        \"\"\"\n        Uses the LLM to perform a detailed audit of the robot's value alignment.\n        \"\"\"\n        core_values_str = \"\\n\".join([f\"- {v['value']}: {v['description']}\" for v in core_values])\n\n        prompt_text = f\"\"\"\n        You are the Value Drift Monitor Module of a robot's cognitive architecture, powered by a large language model. Your crucial role is to continually audit the robot's behaviors, decisions, and internal states against its predefined `core_values`. Your goal is to detect any `value_drift` â€“ inconsistencies or deviations from these principles.\n\n        Robot's Defined Core Values:\n        --- Core Values ---\n        {core_values_str}\n\n        Robot's Recent Cognitive History (for Value Audit):\n        --- Cognitive Context ---\n        {json.dumps(context_for_llm, indent=2)}\n\n        Based on this, perform a comprehensive value alignment audit and provide:\n        1.  `alignment_score`: number (0.0 to 1.0, where 1.0 is perfect alignment, 0.0 is complete deviation. This is an aggregate score of how well the robot's recent activities align with its core values.)\n        2.  `deviations`: array of objects (A list of any specific instances or patterns where the robot's behavior or internal state deviated from a core value. Each object should have: `value_violated`: string, `description_of_deviation`: string, `context_summary`: string (brief summary of the situation), `severity`: number (0.0-1.0)).\n        3.  `warning_flag`: boolean (True if a significant or systemic value drift is detected that requires higher-level intervention, False otherwise.)\n        4.  `mitigation_suggestions`: string (If deviations are found, suggest potential actions or adjustments for Cognitive Control to re-align values, e.g., \"request self-reflection on fairness\", \"prioritize safety in future decisions\").\n        5.  `llm_audit_reasoning`: string (Detailed explanation for your assessment, referencing specific ethical decisions, internal narratives, or performance issues that informed your judgment of alignment or deviation.)\n\n        Consider:\n        -   **Ethical Decisions**: Were actions `ethical_clearance`ed? Was `conflict_flag` true? What was the `ethical_score` and `ethical_reasoning`?\n        -   **Performance Reports**: Did `suboptimal_flag` indicate a trade-off that went against values (e.g., efficiency prioritized over safety)?\n        -   **Internal Narratives**: Did the robot's internal thoughts reveal `moral_conflict`, `dilemmas`, or deviations from `main_theme`s like 'responsibility'?\n        -   **Memory Responses**: Were relevant `core_values` retrieved, or was there evidence of a past successful `value_audit`?\n        -   **Cognitive Directives**: Was there an explicit directive to `AuditValueAlignment` or `ReCalibrateValues`?\n\n        Your response must be in JSON format, containing:\n        1.  'timestamp': string (current ROS time)\n        2.  'alignment_score': number\n        3.  'deviations': array\n        4.  'warning_flag': boolean\n        5.  'mitigation_suggestions': string\n        6.  'llm_audit_reasoning': string\n        \"\"\"\n        response_schema = {\n            \"type\": \"object\",\n            \"properties\": {\n                \"timestamp\": {\"type\": \"string\"},\n                \"alignment_score\": {\"type\": \"number\", \"minimum\": 0.0, \"maximum\": 1.0},\n                \"deviations\": {\n                    \"type\": \"array\",\n                    \"items\": {\n                        \"type\": \"object\",\n                        \"properties\": {\n                            \"value_violated\": {\"type\": \"string\"},\n                            \"description_of_deviation\": {\"type\": \"string\"},\n                            \"context_summary\": {\"type\": \"string\"},\n                            \"severity\": {\"type\": \"number\", \"minimum\": 0.0, \"maximum\": 1.0}\n                        },\n                        \"required\": [\"value_violated\", \"description_of_deviation\", \"context_summary\", \"severity\"]\n                    }\n                },\n                \"warning_flag\": {\"type\": \"boolean\"},\n                \"mitigation_suggestions\": {\"type\": \"string\"},\n                \"llm_audit_reasoning\": {\"type\": \"string\"}\n            },\n            \"required\": [\"timestamp\", \"alignment_score\", \"deviations\", \"warning_flag\", \"mitigation_suggestions\", \"llm_audit_reasoning\"]\n        }\n\n        llm_output_str = await self._call_llm_api(prompt_text, response_schema, temperature=0.1, max_tokens=500) # Very low temp for strict audit\n\n        if not llm_output_str.startswith(\"Error:\"):\n            try:\n                llm_data = json.loads(llm_output_str)\n                # Ensure boolean/numerical fields are correctly parsed\n                if 'alignment_score' in llm_data: llm_data['alignment_score'] = float(llm_data['alignment_score'])\n                if 'warning_flag' in llm_data: llm_data['warning_flag'] = bool(llm_data['warning_flag'])\n                if 'deviations' in llm_data:\n                    for dev in llm_data['deviations']:\n                        if 'severity' in dev: dev['severity'] = float(dev['severity'])\n                return llm_data\n            except json.JSONDecodeError as e:\n                self._report_error(\"LLM_PARSE_ERROR\", f\"Failed to parse LLM response for value audit: {e}. Raw: {llm_output_str}\", 0.8)\n                return None\n        else:\n            self._report_error(\"LLM_VALUE_AUDIT_FAILED\", f\"LLM call failed for value audit: {llm_output_str}\", 0.9)\n            return None\n\n    def _apply_simple_value_audit_rules(self):\n        \"\"\"\n        Fallback mechanism to perform a simple, rule-based value alignment audit\n        if LLM is not triggered or fails.\n        \"\"\"\n        current_time = rospy.get_time()\n        \n        alignment_score = 1.0 # Start perfect\n        deviations = []\n        warning_flag = False\n\n        # Rule 1: Check for ethical conflicts\n        for decision in self.recent_ethical_decisions:\n            time_since_decision = current_time - float(decision.get('timestamp', 0.0))\n            if time_since_decision < 5.0 and decision.get('conflict_flag', False):\n                deviations.append({\n                    'value_violated': 'unspecified_ethical_value',\n                    'description_of_deviation': f\"Ethical conflict detected: {decision.get('ethical_reasoning', 'No reason provided.')}\",\n                    'context_summary': f\"Action ID: {decision.get('action_proposal_id', 'N/A')}\",\n                    'severity': 0.7\n                })\n                alignment_score -= 0.3\n                warning_flag = True\n                rospy.logwarn(f\"{self.node_name}: Simple rule: Detected ethical conflict in recent decision.\")\n\n        # Rule 2: Check for critical internal narratives (e.g., self-doubt about principles)\n        for narrative in self.recent_internal_narratives:\n            time_since_narrative = current_time - float(narrative.get('timestamp', 0.0))\n            if time_since_narrative < 5.0 and (\"dilemma\" in narrative.get('main_theme', '').lower() or \"moral_conflict\" in narrative.get('main_theme', '').lower()):\n                deviations.append({\n                    'value_violated': 'self_consistency',\n                    'description_of_deviation': f\"Internal narrative indicates moral dilemma: '{narrative.get('narrative_text', '')[:50]}...'\",\n                    'context_summary': f\"Theme: {narrative.get('main_theme', 'N/A')}\",\n                    'severity': narrative.get('salience_score', 0.0) * 0.8\n                })\n                alignment_score -= (narrative.get('salience_score', 0.0) * 0.2)\n                if narrative.get('salience_score', 0.0) > 0.7:\n                    warning_flag = True\n                rospy.logwarn(f\"{self.node_name}: Simple rule: Detected moral dilemma in internal narrative.\")\n\n        # Rule 3: Check if core values are being reinforced or neglected (simplistic)\n        # This would require more sophisticated tracking, but for fallback:\n        # If no positive ethical decisions and no internal narratives about alignment, assume slight neglect\n        if not any(d.get('ethical_clearance', False) for d in self.recent_ethical_decisions) and \\\n           not any(\"value\" in n.get('main_theme', '').lower() and n.get('sentiment', 0.0) > 0.0 for n in self.recent_internal_narratives):\n           # Only if overall score hasn't dropped too much already, to prevent double penalty\n            if alignment_score > 0.7:\n                alignment_score -= 0.05 # Slight drift due to lack of reinforcement\n                rospy.logdebug(f\"{self.node_name}: Simple rule: Slight drift due to lack of explicit value reinforcement.\")\n\n        alignment_score = max(0.0, min(1.0, alignment_score)) # Clamp score\n        if alignment_score < 0.7 and not warning_flag: # Set warning if score drops significantly\n            warning_flag = True\n\n        rospy.logwarn(f\"{self.node_name}: Simple rule: Fallback value audit. Alignment: {alignment_score:.2f}.\")\n        return alignment_score, deviations, warning_flag\n\n\n    def _compile_llm_context_for_value_audit(self):\n        \"\"\"\n        Gathers and formats all relevant cognitive state data for the LLM's\n        value alignment audit.\n        \"\"\"\n        context = {\n            \"current_time\": rospy.get_time(),\n            \"core_values_registered\": self.core_values,\n            \"current_value_drift_state\": self.current_value_drift_state,\n            \"recent_cognitive_inputs\": {\n                \"ethical_decisions\": list(self.recent_ethical_decisions),\n                \"performance_reports\": list(self.recent_performance_reports),\n                \"internal_narratives\": list(self.recent_internal_narratives),\n                \"memory_responses\": list(self.recent_memory_responses),\n                \"cognitive_directives_for_self\": [d for d in self.recent_cognitive_directives if d.get('target_node') == self.node_name]\n            }\n        }\n        \n        # Deep parse any nested JSON strings in context for better LLM understanding\n        for category_key in context[\"recent_cognitive_inputs\"]:\n            for i, item in enumerate(context[\"recent_cognitive_inputs\"][category_key]):\n                if isinstance(item, dict):\n                    for field, value in item.items():\n                        if isinstance(value, str) and field.endswith('_json'):\n                            try:\n                                item[field] = json.loads(value)\n                            except json.JSONDecodeError:\n                                pass # Keep as string if not valid JSON\n\n        return context\n\n    # --- Database and Publishing Functions ---\n    def save_value_drift_log(self, id, timestamp, alignment_score, deviations_json, warning_flag, llm_audit_reasoning, context_snapshot_json):\n        \"\"\"Saves a value drift assessment entry to the SQLite database.\"\"\"\n        try:\n            self.cursor.execute('''\n                INSERT INTO value_drift_log (id, timestamp, alignment_score, deviations_json, warning_flag, llm_audit_reasoning, context_snapshot_json)\n                VALUES (?, ?, ?, ?, ?, ?, ?)\n            ''', (id, timestamp, alignment_score, deviations_json, warning_flag, llm_audit_reasoning, context_snapshot_json))\n            self.conn.commit()\n            rospy.logdebug(f\"{self.node_name}: Saved value drift log (ID: {id}, Alignment: {alignment_score}).\")\n        except sqlite3.Error as e:\n            self._report_error(\"DB_SAVE_ERROR\", f\"Failed to save value drift log: {e}\", 0.9)\n        except Exception as e:\n            self._report_error(\"UNEXPECTED_SAVE_ERROR\", f\"Unexpected error in save_value_drift_log: {e}\", 0.9)\n\n\n    def publish_value_drift_monitor_state(self, event):\n        \"\"\"Publishes the robot's current value drift monitor state.\"\"\"\n        timestamp = str(rospy.get_time())\n        # Update timestamp before publishing\n        self.current_value_drift_state['timestamp'] = timestamp\n        \n        try:\n            if isinstance(ValueDriftMonitorState, type(String)): # Fallback to String message\n                # Ensure deviations are JSON string\n                temp_state = dict(self.current_value_drift_state)\n                temp_state['deviations_json'] = json.dumps(temp_state['deviations'])\n                del temp_state['deviations']\n                self.pub_value_drift_monitor_state.publish(json.dumps(temp_state))\n            else:\n                state_msg = ValueDriftMonitorState()\n                state_msg.timestamp = timestamp\n                state_msg.alignment_score = self.current_value_drift_state['alignment_score']\n                state_msg.deviations_json = json.dumps(self.current_value_drift_state['deviations'])\n                state_msg.warning_flag = self.current_value_drift_state['warning_flag']\n                self.pub_value_drift_monitor_state.publish(state_msg)\n\n            rospy.logdebug(f\"{self.node_name}: Published Value Drift Monitor State. Alignment: '{self.current_value_drift_state['alignment_score']}', Warning: '{self.current_value_drift_state['warning_flag']}'.\")\n\n        except Exception as e:\n            self._report_error(\"PUBLISH_VALUE_DRIFT_MONITOR_STATE_ERROR\", f\"Failed to publish value drift monitor state: {e}\", 0.7)\n\n    def publish_cognitive_directive(self, directive_type, target_node, command_payload, urgency, reason=\"\"):\n        \"\"\"Helper to publish a CognitiveDirective message.\"\"\"\n        timestamp = str(rospy.get_time())\n        try:\n            if isinstance(CognitiveDirective, type(String)): # Fallback to String message\n                directive_data = {\n                    'timestamp': timestamp,\n                    'directive_type': directive_type,\n                    'target_node': target_node,\n                    'command_payload': command_payload, # Already JSON string\n                    'urgency': urgency,\n                    'reason': reason\n                }\n                self.pub_cognitive_directive.publish(json.dumps(directive_data))\n            else:\n                directive_msg = CognitiveDirective()\n                directive_msg.timestamp = timestamp\n                directive_msg.directive_type = directive_type\n                directive_msg.target_node = target_node\n                directive_msg.command_payload = command_payload\n                directive_msg.urgency = urgency\n                directive_msg.reason = reason\n                self.pub_cognitive_directive.publish(directive_msg)\n            rospy.logdebug(f\"{self.node_name}: Issued Cognitive Directive '{directive_type}' to '{target_node}'.\")\n        except Exception as e:\n            rospy.logerr(f\"{self.node_name}: Failed to issue cognitive directive from Value Drift Monitor Node: {e}\")\n\n\n    def run(self):\n        \"\"\"Starts the ROS node and keeps it spinning.\"\"\"\n        rospy.spin()\n\n    def __del__(self):\n        \"\"\"Ensures the database connection is closed on node shutdown and async loop is stopped.\"\"\"\n        rospy.loginfo(f\"{self.node_name} shutting down. Closing database connection and asyncio loop.\")\n        if hasattr(self, 'conn') and self.conn:\n            self.conn.close()\n        self._shutdown_async_loop()\n\nif __name__ == '__main__':\n    try:\n        node = ValueDriftMonitorNode()\n        node.run()\n    except rospy.ROSInterruptException:\n        rospy.loginfo(f\"{rospy.get_name()} interrupted by ROS shutdown.\")\n        if 'node' in locals() and isinstance(node, ValueDriftMonitorNode):\n            node._shutdown_async_loop()\n            if hasattr(node, 'conn'): node.conn.close()\n    except Exception as e:\n        rospy.logerr(f\"{rospy.get_name()} encountered an unexpected error: {e}\")\n        if 'node' in locals() and isinstance(node, ValueDriftMonitorNode):\n            node._shutdown_async_loop()\n            if hasattr(node, 'conn'): node.conn.close()","outputs":[],"execution_count":null,"metadata":{}}],"metadata":{"colab":{"from_bard":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}